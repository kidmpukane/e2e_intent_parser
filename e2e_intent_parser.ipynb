{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96beefc6",
   "metadata": {},
   "source": [
    "# **NLP Intent Parser for Industrial Technician Queries**\n",
    "\n",
    "A modular pipeline consisting of:\n",
    "1. Topic Router (LDA, SVM, Mini-BERT)\n",
    "2. Intent + Target + Parameter Token Classifier (DistilBERT, BiLSTM, LSTM)\n",
    "3. Context Resolver for domain-aware refinement\n",
    "\n",
    "This notebook demonstrates preprocessing, embeddings, token labeling, \n",
    "three different modeling strategies, evaluation, and comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e9f4d",
   "metadata": {},
   "source": [
    "### **1. Import and Setup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f79d0ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (25.3)\n",
      "Requirement already satisfied: pip in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (25.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "239e4f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: torch in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: transformers in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (6.33.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn nltk torch seaborn matplotlib transformers tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0371b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (6.33.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (2.2.6)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lwand\\onedrive\\documents\\projects\\e2e_intent_parser\\eienv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f887bfce",
   "metadata": {},
   "source": [
    "**Why We Generated the Dataset Ourselves**\n",
    "\n",
    "There isn’t any publicly available dataset that captures \"technician-style\" micro-grid instructions with the level of structure we need (intent, target, parameter, modifier, conditions). Real industrial datasets are either private, messy, and rarely come with clean labels or ones we can make sense of. Since our goal here is to benchmark different NLP models, not to clean handwritten maintenance logs, synthetic data gives us full control over the balance, coverage, and consistency.\n",
    "\n",
    "It lets us shape the exact problem in the manner that we want to model, and it’s standard practice during early prototyping before fine-tuning on real operational data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51647e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lwand\\OneDrive\\Documents\\Projects\\e2e_intent_parser\\eienv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963e706",
   "metadata": {},
   "source": [
    "### **2. Data Exploration (EDA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9cb0e7",
   "metadata": {},
   "source": [
    "**The first step is to confirm formatting and make sure all columns loaded correctly.**\n",
    "\n",
    "*Our EDA focuses on validating distribution, coverage, and linguistic variety across intents, targets, and parameters. Since the dataset is synthetic, the goal isn’t noise inspection but ensuring balance, realism, and sufficient diversity to train and compare NLP models reliably.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de2acac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/solar_ds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c24f540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>intent</th>\n",
       "      <th>target</th>\n",
       "      <th>parameter</th>\n",
       "      <th>modifier</th>\n",
       "      <th>conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Log irradiance readings on the inverter.</td>\n",
       "      <td>log</td>\n",
       "      <td>inverter</td>\n",
       "      <td>irradiance</td>\n",
       "      <td>overload</td>\n",
       "      <td>during_peak_hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Monitor microgrid_controller — temperature see...</td>\n",
       "      <td>monitor</td>\n",
       "      <td>microgrid_controller</td>\n",
       "      <td>temperature</td>\n",
       "      <td>sudden_drop</td>\n",
       "      <td>during_peak_hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inspect inverter — efficiency seems critical.</td>\n",
       "      <td>inspect</td>\n",
       "      <td>inverter</td>\n",
       "      <td>efficiency</td>\n",
       "      <td>critical</td>\n",
       "      <td>during_peak_hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Optimize anomaly in inverter temperature.</td>\n",
       "      <td>optimize</td>\n",
       "      <td>inverter</td>\n",
       "      <td>temperature</td>\n",
       "      <td>high</td>\n",
       "      <td>at_night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reset anomaly in battery_bank temperature.</td>\n",
       "      <td>reset</td>\n",
       "      <td>battery_bank</td>\n",
       "      <td>temperature</td>\n",
       "      <td>high</td>\n",
       "      <td>under_cloud_cover</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query    intent  \\\n",
       "0           Log irradiance readings on the inverter.       log   \n",
       "1  Monitor microgrid_controller — temperature see...   monitor   \n",
       "2      Inspect inverter — efficiency seems critical.   inspect   \n",
       "3          Optimize anomaly in inverter temperature.  optimize   \n",
       "4         Reset anomaly in battery_bank temperature.     reset   \n",
       "\n",
       "                 target    parameter     modifier         conditions  \n",
       "0              inverter   irradiance     overload  during_peak_hours  \n",
       "1  microgrid_controller  temperature  sudden_drop  during_peak_hours  \n",
       "2              inverter   efficiency     critical  during_peak_hours  \n",
       "3              inverter  temperature         high           at_night  \n",
       "4          battery_bank  temperature         high  under_cloud_cover  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d566f538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>intent</th>\n",
       "      <th>target</th>\n",
       "      <th>parameter</th>\n",
       "      <th>modifier</th>\n",
       "      <th>conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>Inspect anomaly in inverter fault_code.</td>\n",
       "      <td>inspect</td>\n",
       "      <td>inverter</td>\n",
       "      <td>fault_code</td>\n",
       "      <td>low</td>\n",
       "      <td>under_cloud_cover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>Diagnose current readings on the grid_tie_inve...</td>\n",
       "      <td>diagnose</td>\n",
       "      <td>grid_tie_inverter</td>\n",
       "      <td>current</td>\n",
       "      <td>overload</td>\n",
       "      <td>post_storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884</th>\n",
       "      <td>Reset issue detected in inverter fault_code.</td>\n",
       "      <td>reset</td>\n",
       "      <td>inverter</td>\n",
       "      <td>fault_code</td>\n",
       "      <td>critical</td>\n",
       "      <td>at_night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>Log anomaly in battery_bank output_power.</td>\n",
       "      <td>log</td>\n",
       "      <td>battery_bank</td>\n",
       "      <td>output_power</td>\n",
       "      <td>critical</td>\n",
       "      <td>during_peak_hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>Reset issue detected in charge_controller faul...</td>\n",
       "      <td>reset</td>\n",
       "      <td>charge_controller</td>\n",
       "      <td>fault_code</td>\n",
       "      <td>critical</td>\n",
       "      <td>at_night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query    intent  \\\n",
       "1059            Inspect anomaly in inverter fault_code.   inspect   \n",
       "4962  Diagnose current readings on the grid_tie_inve...  diagnose   \n",
       "3884       Reset issue detected in inverter fault_code.     reset   \n",
       "3086          Log anomaly in battery_bank output_power.       log   \n",
       "3761  Reset issue detected in charge_controller faul...     reset   \n",
       "\n",
       "                 target     parameter  modifier         conditions  \n",
       "1059           inverter    fault_code       low  under_cloud_cover  \n",
       "4962  grid_tie_inverter       current  overload         post_storm  \n",
       "3884           inverter    fault_code  critical           at_night  \n",
       "3086       battery_bank  output_power  critical  during_peak_hours  \n",
       "3761  charge_controller    fault_code  critical           at_night  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e38c52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   query       5000 non-null   object\n",
      " 1   intent      5000 non-null   object\n",
      " 2   target      5000 non-null   object\n",
      " 3   parameter   5000 non-null   object\n",
      " 4   modifier    5000 non-null   object\n",
      " 5   conditions  5000 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d124a1a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "591ecfe4",
   "metadata": {},
   "source": [
    "### **3. Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e0a123",
   "metadata": {},
   "source": [
    "This section transforms raw queries into model-ready inputs for both the classical LSTM/BiLSTM pipeline and the BERT pipeline.\n",
    "\n",
    "We only perform necessary cleaning steps as the synthetic data is already consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5082f9",
   "metadata": {},
   "source": [
    "##### **3.1 Normalisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb2cab",
   "metadata": {},
   "source": [
    "Even though the dataset is synthetic, we will apply minimal normalisation for consistency across models:\n",
    "\n",
    "Lowercasing (for LSTM/BiLSTM only — BERT does its own thing)\n",
    "\n",
    "Strip extra whitespace\n",
    "\n",
    "Optional punctuation spacing (only if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ae5147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(text):\n",
    "    return \" \".join(text.lower().strip().split())\n",
    "\n",
    "df[\"text_norm\"] = df[\"query\"].apply(normalise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6936ed68",
   "metadata": {},
   "source": [
    "##### **3.2 Train/Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8e4799a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (4000, 7), Test shape: (1000, 7)\n",
      "intent\n",
      "check       489\n",
      "diagnose    492\n",
      "inspect     472\n",
      "log         531\n",
      "monitor     469\n",
      "optimize    541\n",
      "predict     509\n",
      "reset       497\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"intent\"]\n",
    ")\n",
    "print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
    "\n",
    "grouped = train_df.groupby('intent').size()\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa897a",
   "metadata": {},
   "source": [
    "##### **3.3 Labels for Intent, Target, Parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc429acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent to ID mapping:\n",
      "{'log': 0, 'monitor': 1, 'inspect': 2, 'optimize': 3, 'reset': 4, 'predict': 5, 'diagnose': 6, 'check': 7}\n",
      "\n",
      "Target to ID mapping:\n",
      "{'inverter': 0, 'microgrid_controller': 1, 'battery_bank': 2, 'solar_panel': 3, 'smart_meter': 4, 'pv_array': 5, 'grid_tie_inverter': 6, 'charge_controller': 7}\n",
      "\n",
      "Parameter to ID mapping:\n",
      "{'irradiance': 0, 'temperature': 1, 'efficiency': 2, 'state_of_charge': 3, 'fault_code': 4, 'output_power': 5, 'voltage': 6, 'frequency': 7, 'load_balance': 8, 'current': 9}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "intent2id = {lbl: i for i, lbl in enumerate(df[\"intent\"].unique())}\n",
    "target2id = {lbl: i for i, lbl in enumerate(df[\"target\"].unique())}\n",
    "param2id = {lbl: i for i, lbl in enumerate(df[\"parameter\"].unique())}\n",
    "\n",
    "df[\"intent_id\"] = df[\"intent\"].map(intent2id)\n",
    "df[\"target_id\"] = df[\"target\"].map(target2id)\n",
    "df[\"param_id\"] = df[\"parameter\"].map(param2id)\n",
    "\n",
    "# Print the mappings\n",
    "print(\"Intent to ID mapping:\")\n",
    "print(intent2id)\n",
    "print(\"\\nTarget to ID mapping:\")\n",
    "print(target2id)\n",
    "print(\"\\nParameter to ID mapping:\")\n",
    "print(param2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a59818",
   "metadata": {},
   "source": [
    "##### **3.4 Tokenisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e95f50",
   "metadata": {},
   "source": [
    "**A) Classical (LSTM/Bi-LSTM) Tokeniser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e511bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tk = Tokenizer(num_words=20000, oov_token=\"<UNK>\")\n",
    "tk.fit_on_texts(train_df[\"text_norm\"])\n",
    "\n",
    "train_seq = tk.texts_to_sequences(train_df[\"text_norm\"])\n",
    "test_seq = tk.texts_to_sequences(test_df[\"text_norm\"])\n",
    "\n",
    "MAX_LEN = 32\n",
    "train_seq = pad_sequences(train_seq, maxlen=MAX_LEN, padding=\"post\")\n",
    "test_seq = pad_sequences(test_seq, maxlen=MAX_LEN, padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a74cfa",
   "metadata": {},
   "source": [
    "**B) BERT Tokenizer (HuggingFace)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "826cd2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "bert_tok = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "\n",
    "def encode_batch(texts):\n",
    "    return bert_tok(\n",
    "        texts.tolist(),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "\n",
    "train_bert = encode_batch(train_df[\"query\"])\n",
    "test_bert = encode_batch(test_df[\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac202b8",
   "metadata": {},
   "source": [
    "##### **3.5 Final Training Dictionaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc4a40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       1\n",
      "2       2\n",
      "3       3\n",
      "4       4\n",
      "       ..\n",
      "4995    4\n",
      "4996    3\n",
      "4997    0\n",
      "4998    0\n",
      "4999    0\n",
      "Name: intent_id, Length: 5000, dtype: int64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'intent_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lwand\\OneDrive\\Documents\\Projects\\e2e_intent_parser\\eienv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'intent_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintent_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      3\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintent_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      9\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintent\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintent_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m     13\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\lwand\\OneDrive\\Documents\\Projects\\e2e_intent_parser\\eienv\\lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\lwand\\OneDrive\\Documents\\Projects\\e2e_intent_parser\\eienv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3817\u001b[0m     ):\n\u001b[0;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'intent_id'"
     ]
    }
   ],
   "source": [
    "print(df[\"intent_id\"].value_counts())\n",
    "\n",
    "train_labels = {\n",
    "    \"intent\": train_df[\"intent_id\"].values,\n",
    "    \"target\": train_df[\"target_id\"].values,\n",
    "    \"parameter\": train_df[\"param_id\"].values,\n",
    "}\n",
    "\n",
    "test_labels = {\n",
    "    \"intent\": test_df[\"intent_id\"].values,\n",
    "    \"target\": test_df[\"target_id\"].values,\n",
    "    \"parameter\": test_df[\"param_id\"].values,\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eienv (3.10.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
